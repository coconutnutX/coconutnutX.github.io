<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    
    <title>看源码笔记 DeephageTP | CoCoNutNut&#39;s NoteBook</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    

    
        <meta property="algolia:search" data-application-id="TEBQDP8EUP" data-api-key="ce44cbe0f6cb711854c1df404fd28ab1" data-index-name="coconutnutx">
    

    

    

    

    

    

    
<link rel="stylesheet" href="/dist/build.css?v=1633679241878.css">


    
<link rel="stylesheet" href="/dist/custom.css?v=1633679241878.css">


    <script>
        window.isPost = true
        window.aomori = {
            
            
            
        }
        window.aomori_logo_typed_animated = false
        window.aomori_search_algolia = true

    </script>

<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="CoCoNutNut's NoteBook" type="application/atom+xml">
</head>

<body>

    <div class="container">
    <header class="header">
        <div class="header-type">
            
            <div class="header-type-inner">
                
                    <a class="header-type-title" href="/">CoCoNutNut&#39;s NoteBook</a>
                
    
                
            </div>
        </div>
        <div class="header-menu">
            <div class="header-menu-inner">
                
            </div>
            <div class="header-menu-social">
                
            </div>
        </div>

        <div class="header-menu-mobile">
            <div class="header-menu-mobile-inner" id="mobile-menu-open">
                <i class="icon icon-menu"></i>
            </div>
        </div>
    </header>

    <div class="header-menu-mobile-menu">
        <div class="header-menu-mobile-menu-bg"></div>
        <div class="header-menu-mobile-menu-wrap">
            <div class="header-menu-mobile-menu-inner">
                <div class="header-menu-mobile-menu-close" id="mobile-menu-close">
                    <i class="icon icon-cross"></i>
                </div>
                <div class="header-menu-mobile-menu-list">
                    
                </div>
            </div>
        </div>
    </div>

</div>

    <div class="container">
        <div class="main">
            <section class="inner">
                <section class="inner-main">
                    <div class="post">
    <article id="post-ckw1zv19z0089ukqdaywb39ur" class="article article-type-post" itemscope
    itemprop="blogPost">

    <div class="article-inner">

        
          
        
        
        

        
        <header class="article-header">
            
  
    <h1 class="article-title" itemprop="name">
      看源码笔记 DeephageTP
    </h1>
  

        </header>
        

        <div class="article-more-info article-more-info-post hairline">

            <div class="article-date">
  <time datetime="2020-11-19T16:02:01.000Z" itemprop="datePublished">2020-11-19</time>
</div>

            
            <div class="article-category">
                <a class="article-category-link" href="/categories/Note/">Note</a>
            </div>
            

            
            <div class="article-tag">
                <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/bioinformatics/" rel="tag">bioinformatics</a></li></ul>
            </div>
            

            

        </div>

        <div class="article-entry post-inner-html hairline" itemprop="articleBody">
            <blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/chuym726/DeephageTP">https://github.com/chuym726/DeephageTP</a></p>
</blockquote>
<h1 id="环境搭建-amp-数据准备"><a href="#环境搭建-amp-数据准备" class="headerlink" title="环境搭建&amp;数据准备"></a>环境搭建&amp;数据准备</h1><p>（已有：conda 4.9.2）</p>
<ol>
<li><p>下载<a target="_blank" rel="noopener" href="https://github.com/chuym726/DeephageTP">https://github.com/chuym726/DeephageTP</a></p>
</li>
<li><p>创建新的虚拟环境deephageTP</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --name deephageTP python=3.6 numpy theano keras scikit-learn</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>新建工程文件夹DeephageTP-test（需要的文件从下载的DeephageTP-master拷）</p>
</li>
<li><p>PyCharm打开DeephageTP-test，激活环境</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate deephageTP</span><br></pre></td></tr></table></figure>

<img src="/images/2020/screencapture2020-11-19 PM5.23.40.jpg">

<p>Python Interpreter也改成deephageTP</p>
<img src="/images/2020/screencapture2020-11-19 PM5.25.35.jpg">

<img src="/images/2020/screencapture2020-11-19 PM5.26.51.jpg">

<h1 id="测试example-data-fa"><a href="#测试example-data-fa" class="headerlink" title="测试example_data.fa"></a>测试example_data.fa</h1><p>代码里面直接读的training_data.faa，X和Y应该在同一个文件里，</p>
<p>但是给的training_data.faa.X.npy.tar.gz、training_data.faa.Y.npy.tar.gz是在不同文件</p>
<p>于是先用example_data.fa试一下（遇到bug #1，解决见Debug）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">(deephageTP) coconutnut@x86_64-apple-darwin13 DeephageTP-test % python DeephageTP_model_training.py</span><br><span class="line">Using TensorFlow backend.</span><br><span class="line">only amino acid code.</span><br><span class="line">ok! there is the same number (193) of labels and sequences. </span><br><span class="line">193</span><br><span class="line">193</span><br><span class="line">193</span><br><span class="line">ok! windows is 900.</span><br><span class="line">ok! raw data has been saved as a npy file example_data.fa.X/Y</span><br><span class="line">now runing is DL_Train.</span><br><span class="line">nb_filters:  50</span><br><span class="line">kernel_s:  3</span><br><span class="line">n_batch:  10</span><br><span class="line">n_echos:  20</span><br><span class="line">dropout1:  0.1</span><br><span class="line">dropout2:  0.1</span><br><span class="line">ok! the npy file example_data.fa.X/Y.npy are loaded!</span><br><span class="line">ok! all labels are in 4 kinds.</span><br><span class="line">193</span><br><span class="line">now training for all, Be noted here no test part !!!</span><br><span class="line">[[1. 0. 0. 0.]</span><br><span class="line"> [1. 0. 0. 0.]</span><br><span class="line"> [1. 0. 0. 0.]</span><br><span class="line">......</span><br><span class="line"> [0. 0. 0. 1.]</span><br><span class="line"> [0. 0. 0. 1.]</span><br><span class="line"> [0. 0. 0. 1.]</span><br><span class="line"> [0. 0. 0. 1.]]</span><br><span class="line">2020-11-19 17:30:03.895070: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class="line">To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.</span><br><span class="line">2020-11-19 17:30:03.895316: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.</span><br><span class="line">Epoch 1/20</span><br><span class="line">193/193 [==============================] - 12s 64ms/step - loss: 1.1962 - accuracy: 0.4767</span><br><span class="line">Epoch 2/20</span><br><span class="line">193/193 [==============================] - 11s 55ms/step - loss: 0.4503 - accuracy: 0.8446</span><br><span class="line">Epoch 3/20</span><br><span class="line">193/193 [==============================] - 10s 53ms/step - loss: 0.1844 - accuracy: 0.9534</span><br><span class="line">Epoch 4/20</span><br><span class="line">193/193 [==============================] - 10s 52ms/step - loss: 0.1079 - accuracy: 0.9845</span><br><span class="line">Epoch 5/20</span><br><span class="line">193/193 [==============================] - 11s 55ms/step - loss: 0.0383 - accuracy: 1.0000</span><br><span class="line">Epoch 6/20</span><br><span class="line">193/193 [==============================] - 10s 50ms/step - loss: 0.0203 - accuracy: 1.0000</span><br><span class="line">Epoch 7/20</span><br><span class="line">193/193 [==============================] - 12s 61ms/step - loss: 0.0105 - accuracy: 1.0000</span><br><span class="line">Epoch 8/20</span><br><span class="line">193/193 [==============================] - 10s 51ms/step - loss: 0.0063 - accuracy: 1.0000</span><br><span class="line">Epoch 9/20</span><br><span class="line">193/193 [==============================] - 10s 51ms/step - loss: 0.0058 - accuracy: 1.0000</span><br><span class="line">Epoch 10/20</span><br><span class="line">193/193 [==============================] - 10s 50ms/step - loss: 0.0104 - accuracy: 0.9948</span><br><span class="line">Epoch 11/20</span><br><span class="line">193/193 [==============================] - 10s 51ms/step - loss: 0.0066 - accuracy: 1.0000</span><br><span class="line">Epoch 12/20</span><br><span class="line">193/193 [==============================] - 10s 51ms/step - loss: 0.0041 - accuracy: 1.0000</span><br><span class="line">Epoch 13/20</span><br><span class="line">193/193 [==============================] - 10s 52ms/step - loss: 0.0017 - accuracy: 1.0000</span><br><span class="line">Epoch 14/20</span><br><span class="line">193/193 [==============================] - 10s 50ms/step - loss: 0.0026 - accuracy: 1.0000</span><br><span class="line">Epoch 15/20</span><br><span class="line">193/193 [==============================] - 10s 51ms/step - loss: 0.0017 - accuracy: 1.0000</span><br><span class="line">Epoch 16/20</span><br><span class="line">193/193 [==============================] - 10s 50ms/step - loss: 0.0013 - accuracy: 1.0000</span><br><span class="line">Epoch 17/20</span><br><span class="line">193/193 [==============================] - 10s 52ms/step - loss: 0.0011 - accuracy: 1.0000</span><br><span class="line">Epoch 18/20</span><br><span class="line">193/193 [==============================] - 9s 48ms/step - loss: 8.4943e-04 - accuracy: 1.0000</span><br><span class="line">Epoch 19/20</span><br><span class="line">193/193 [==============================] - 9s 49ms/step - loss: 8.9927e-04 - accuracy: 1.0000</span><br><span class="line">Epoch 20/20</span><br><span class="line">193/193 [==============================] - 9s 49ms/step - loss: 0.0011 - accuracy: 1.0000</span><br><span class="line">the model (example_data.fa.all.h5) has saved!</span><br></pre></td></tr></table></figure>

<p>产生了3个文件</p>
<p>example_data.fa.all.h5</p>
<p>example_data.fa.X.npy</p>
<p>example_data.fa.Y.npy</p>
<p>所以给的training_data.faa.X.npy.tar.gz、training_data.faa.Y.npy.tar.gz也是生成的吗？data文件夹里就一个叫a的空文件，难道是没传training_data.faa？😧</p>
<p>看了下代码，还真是🙄</p>
<p>aa_ref2npy()用来转格式，存成one-hot编码后，X和Y分开的形式</p>
<p>DL_Train()用来训练</p>
<p>既然如此，直接用training_data.faa.X.npy.tar.gz、training_data.faa.Y.npy.tar.gz解压，不跑aa_ref2npy()，就可以直接训练了</p>
<h1 id="测试training-data-faa"><a href="#测试training-data-faa" class="headerlink" title="测试training_data.faa"></a>测试training_data.faa</h1><p>解压training_data.faa.X.npy.tar.gz、training_data.faa.Y.npy.tar.gz</p>
<p>（25.3MB解压后3.97 GB，是得有多少0啊，不愧是one-hot）</p>
<p>代码改了2处：</p>
<p>第8行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.cross_validation import train_test_split</span><br></pre></td></tr></table></figure>

<p>改成</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import train_test_split</span><br></pre></td></tr></table></figure>

<p>最后的</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if 1:</span><br><span class="line">	aa_ref2npy(ref_Data=ref_Data,len_w=len_w)</span><br></pre></td></tr></table></figure>

<p>注释掉</p>
<p>运行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">(deephageTP) coconutnut@x86_64-apple-darwin13 DeephageTP-test % python DeephageTP_model_training.py</span><br><span class="line">Using TensorFlow backend.</span><br><span class="line">only amino acid code.</span><br><span class="line">now runing is DL_Train.</span><br><span class="line">nb_filters:  50</span><br><span class="line">kernel_s:  3</span><br><span class="line">n_batch:  10</span><br><span class="line">n_echos:  20</span><br><span class="line">dropout1:  0.1</span><br><span class="line">dropout2:  0.1</span><br><span class="line">ok! the npy file training_data.faa.X/Y.npy are loaded!</span><br><span class="line">ok! all labels are in 4 kinds.</span><br><span class="line">27585</span><br><span class="line">now training for all, Be noted here no test part !!!</span><br><span class="line">[[1. 0. 0. 0.]</span><br><span class="line"> [1. 0. 0. 0.]</span><br><span class="line"> [1. 0. 0. 0.]</span><br><span class="line"> ...</span><br><span class="line"> [0. 0. 0. 1.]</span><br><span class="line"> [0. 0. 0. 1.]</span><br><span class="line"> [0. 0. 0. 1.]]</span><br><span class="line">2020-11-19 17:52:30.350217: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class="line">To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.</span><br><span class="line">2020-11-19 17:52:30.350529: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.</span><br><span class="line">Epoch 1/20</span><br><span class="line"> 1250/27585 [&gt;.............................] - ETA: 22:33 - loss: 0.5788 - accuracy: 0.8016</span><br></pre></td></tr></table></figure>

<p>太大了，不跑了</p>
<h1 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h1><p>训练部分 DeephageTP_model_training.py</p>
<h2 id="aa-ref2npy"><a href="#aa-ref2npy" class="headerlink" title="aa_ref2npy()"></a>aa_ref2npy()</h2><p>做one-hot编码用的</p>
<p>把蛋白质序列↓</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;UniRef100_A0A017QK57 PBSX family phage terminase large subunit n=1 Tax=Glaesserella parasuis str. Nagasaki TaxID=1117322 RepID=A0A017QK57_HAEPR 1</span><br><span class="line">MKIQLNLPPKLIPVFTQQNVRYRGAYGGRGSAKTRTFAKMTAVVAYQRAMQGESGVILCGREFMNSLEDSSLEEIKQAIQSEPWLTDFFEVGEKYVRTKCGRISYIFTGLRHNLDSIKSKARILLAWIDEAESVSEMAWRKLLPTVRENGSEIWLTWNPEKKGSATDLRFRQHQDESMAIVEMNYSDNPWFPDVLEQERLRDKARLDDATYRWIWEGAYLEQSEAQIFRDKFQELEFKPNGDFSGPYFGLDFGFAQDPTAAVKCWVFKDELYIEYEAGKVGLELDDTATFLQKGIVGIEQYVIRADSARPESISYLKRHGLPRIDGVSKWKGSVEDGIAHIKSYKKIYIHPRCQQTLNEFRLYSYKTDRLSGDILPVVLDENNHYIDALRYALEPLMKGRQSWFG</span><br></pre></td></tr></table></figure>

<p>one-hot编码，np.array格式，保存（分别存X和Y）</p>
<p>把X打出来看下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  对应M</span><br><span class="line"> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  对应K</span><br><span class="line"> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  对应I</span><br><span class="line"> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],</span><br><span class="line"> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],</span><br><span class="line"> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],</span><br><span class="line"> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>

<p>就是和蛋白质序列MKI…一一对应的one-hot编码（还是手动写死的）</p>
<p>大小是(900, 20)，和文中描述一样</p>
<p>这里Y是0，根据每个蛋白质第一行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;UniRef100_A0A017QK57 PBSX family phage terminase large subunit n=1 Tax=Glaesserella parasuis str. Nagasaki TaxID=1117322 RepID=A0A017QK57_HAEPR 1</span><br></pre></td></tr></table></figure>

<p>最后这个数字-1表示类别</p>
<p>如下面这个蛋白的类别是2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;UniRef100_A0A072NPV4 Phage terminase, small subunit n=1 Tax=Bacillus azotoformans MEV2011 TaxID=1348973 RepID=A0A072NPV4_BACAZ 3</span><br><span class="line">MAKDGTNRGGARVGAGAKKKPLTDKIAEGNPGGRKLTVMEFKDTADLKGLEMPEPNKMLEAIQKDGKALVAGEIYRNTWAWLNERGCAALVSPQLLERYAMSVARWIQCEEAVTEYGFLAKHPTTGNAIQSPYVAMGQNYMNQTNRLWMEIFQIVKENCTGEYSGINPQDDVMERLLTARRGK</span><br></pre></td></tr></table></figure>

<h2 id="DL-Train"><a href="#DL-Train" class="headerlink" title="DL_Train()"></a>DL_Train()</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DL_Train</span>(<span class="params">ref_Data, len_w</span>):</span></span><br><span class="line">	<span class="comment"># 参数设置</span></span><br><span class="line">	nb_filters = <span class="number">50</span></span><br><span class="line">	kernel_s = <span class="number">3</span></span><br><span class="line">	n_batch = <span class="number">10</span></span><br><span class="line">	n_echos = <span class="number">20</span></span><br><span class="line">	dropout1 = <span class="number">0.10</span></span><br><span class="line">	dropout2 = <span class="number">0.10</span></span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&quot;now runing is DL_Train.&quot;</span>)</span><br><span class="line">		<span class="comment"># end_lossrint(&quot;all is ended.&quot;)</span></span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&quot;nb_filters: &quot;</span>, nb_filters)</span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&quot;kernel_s: &quot;</span>, kernel_s)</span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&quot;n_batch: &quot;</span>, n_batch)</span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&quot;n_echos: &quot;</span>, n_echos)</span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&quot;dropout1: &quot;</span>, dropout1)</span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&quot;dropout2: &quot;</span>, dropout2)</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 处理数据</span></span><br><span class="line">	X2 = np.load(ref_Data + <span class="string">&quot;.X.npy&quot;</span>)</span><br><span class="line">	Y2 = np.load(ref_Data + <span class="string">&quot;.Y.npy&quot;</span>)</span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&quot;ok! the npy file &quot;</span> + ref_Data + <span class="string">&quot;.X/Y.npy are loaded!&quot;</span> )</span><br><span class="line">	n_classes = <span class="number">4</span>    <span class="comment">#len(np.unique(Y))</span></span><br><span class="line">	<span class="built_in">print</span> (<span class="string">&quot;ok! all labels are in &quot;</span> + <span class="built_in">str</span>(n_classes) + <span class="string">&quot; kinds.&quot;</span> )</span><br><span class="line">	YY_t = []</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> Y2:</span><br><span class="line">		ll = np.zeros(n_classes)</span><br><span class="line">		ll[i] = <span class="number">1</span></span><br><span class="line">		YY_t.append(ll)</span><br><span class="line">	YY_t = np.array(YY_t)</span><br><span class="line">	<span class="built_in">print</span>(<span class="built_in">len</span>(YY_t))</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;now training for all, Be noted here no test part !!!&quot;</span>)</span><br><span class="line">	X_train = X2.reshape(-<span class="number">1</span>,<span class="number">1</span>,len_w,matrix_size)</span><br><span class="line">	Y_train = YY_t</span><br><span class="line">	<span class="built_in">print</span>(Y_train)</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 构建模型</span></span><br><span class="line">	model = Sequential()</span><br><span class="line">	model.add(Conv2D(filters=nb_filters,kernel_size=(<span class="number">7</span>,<span class="number">1</span>),padding=<span class="string">&#x27;same&#x27;</span>,input_shape=(<span class="number">1</span>,len_w,matrix_size),data_format=<span class="string">&#x27;channels_first&#x27;</span>))</span><br><span class="line">	model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">	model.add(MaxPooling2D(pool_size=(<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">	model.add(Dropout(dropout1))</span><br><span class="line">	model.add(Flatten())</span><br><span class="line">	model.add(Dense(<span class="number">100</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">	model.add(Dropout(dropout2))</span><br><span class="line">	model.add(Dense(n_classes,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">	model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,optimizer=Adam(),metrics=[<span class="string">&#x27;accuracy&#x27;</span>])   </span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 训练模型</span></span><br><span class="line">	model.fit(X_train,Y_train,batch_size=n_batch,epochs=n_echos,verbose=<span class="number">1</span>)</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 保存模型</span></span><br><span class="line">	model.save(ref_Data + <span class="string">&#x27;.all.h5&#x27;</span>)</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;the model (&quot;</span> + ref_Data + <span class="string">&quot;.all.h5) has saved!&quot;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h1><h3 id="1"><a href="#1" class="headerlink" title="#1"></a>#1</h3><p>第一次跑DeephageTP_model_training.py时遇到的bug</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ModuleNotFoundError: No module named &#x27;sklearn.cross_validation&#x27;</span><br></pre></td></tr></table></figure>

<p>解决：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35962520/article/details/85295228">https://blog.csdn.net/qq_35962520/article/details/85295228</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># from sklearn.cross_validation import train_test_split # cross_validation不再使用，移至model_selection</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br></pre></td></tr></table></figure>


        </div>

    </div>

    

    

    

    

    

    
<nav class="article-nav">
  
    <a href="/2020/11/30/note-unity/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-caption">下一篇</div>
      <div class="article-nav-title">
        
          Unity笔记 Project01 Basic
        
      </div>
    </a>
  
  
    <a href="/2020/11/19/paper-note/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-caption">上一篇</div>
      <div class="article-nav-title">读论文笔记 DeephageTP</div>
    </a>
  
</nav>


    <section class="share">
        <div class="share-title">分享</div>
        <a class="share-item" target="_blank"
            href="https://twitter.com/share?text=看源码笔记 DeephageTP - CoCoNutNut's NoteBook&url=http://yoursite.com/2020/11/19/code-note/">
            <box-icon type='logo' name='twitter'></box-icon>
        </a>
        <a class="share-item" target="_blank"
            href="https://www.facebook.com/sharer.php?title=看源码笔记 DeephageTP - CoCoNutNut's NoteBook&u=http://yoursite.com/2020/11/19/code-note/">
            <box-icon name='facebook-square' type='logo' ></box-icon>
        </a>
        <!-- <a class="share-item" target="_blank"
            href="https://service.weibo.com/share/share.php?title=看源码笔记 DeephageTP - CoCoNutNut's NoteBook&url=http://yoursite.com/2020/11/19/code-note/&pic=">
            <div class="n-icon n-icon-weibo"></div>
        </a> -->
    </section>

</article>












</div>
                </section>
            </section>

            
            <aside class="sidebar sidebar-search-fix">
                

    <div class="search">
    <div class="has-icon-right">
        <input type="text" class="form-input" id="search" placeholder="SEARCH" autocomplete="off">
        <div class="form-icon">
            <box-icon name='search' color="#3c4859"></box-icon>
        </div>
    </div>
    <div class="search-result" id="search-ps"></div>
</div>


<div class="widget" id="widget">
    
      
  <div class="widget-wrap">
    <div class="widget-inner">
      <div class="toc post-toc-html"></div>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-cate">
    <div class="widget-title"><span>Categories</span></div>
    <div class="widget-inner">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Debug/">Debug</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Memo/">Memo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Note/">Note</a></li></ul>
    </div>
  </div>


    
      
  <div class="widget-wrap widget-tags">
    <div class="widget-title"><span>Tags</span></div>
    <div class="widget-inner">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithm/" rel="tag">algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ar/" rel="tag">ar</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bioinformatics/" rel="tag">bioinformatics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/concurrent-algorithm/" rel="tag">concurrent_algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/distributed-algorithm/" rel="tag">distributed_algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mindmap/" rel="tag">mindmap</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mybatis/" rel="tag">mybatis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mybatis-plus/" rel="tag">mybatis_plus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spring/" rel="tag">spring</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/springcloud/" rel="tag">springcloud</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/springmvc/" rel="tag">springmvc</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sublinear-algorithm/" rel="tag">sublinear_algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tool/" rel="tag">tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/unity/" rel="tag">unity</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vue/" rel="tag">vue</a></li></ul>
    </div>
  </div>


    
      
  <div class="widget-wrap widget-recent-posts">
    <div class="widget-title"><span>Recent Posts</span></div>
    <div class="widget-inner">
      <ul>
        
          <li>
            <a href="/2021/11/16/algolia/">更改主题记录</a>
          </li>
        
          <li>
            <a href="/2021/11/13/concurrent2/">sync example note2：memory order</a>
          </li>
        
          <li>
            <a href="/2021/11/13/concurrent/">sync example note1</a>
          </li>
        
          <li>
            <a href="/2021/10/31/register/">Summary on basic register reductions</a>
          </li>
        
          <li>
            <a href="/2021/10/27/countsketch/">CountSketch Matrix</a>
          </li>
        
      </ul>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-archive">
    <div class="widget-title"><span>Archive</span></div>
    <div class="widget-inner">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a></li></ul>
    </div>
  </div>


    
</div>

<div id="backtop"><i class="icon icon-arrow-up"></i></div>
            </aside>
            
        </div>
    </div>

    <footer class="footer">
    <div class="footer-wave">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1440 320"><path fill="#3c4859" fill-opacity="1" d="M0,160L60,181.3C120,203,240,245,360,240C480,235,600,181,720,186.7C840,192,960,256,1080,261.3C1200,267,1320,213,1380,186.7L1440,160L1440,320L1380,320C1320,320,1200,320,1080,320C960,320,840,320,720,320C600,320,480,320,360,320C240,320,120,320,60,320L0,320Z"></path></svg>
    </div>

    <div class="footer-wrap">
        <div class="footer-inner"> 
            CoCoNutNut&#39;s NoteBook &copy; 2021<br>
            Powered By Hexo · Theme By <a href="https://github.com/lh1me/hexo-theme-aomori" target="_blank">Aomori</a>
        </div>
    </div>

</footer>






<script src="/dist/build.js?1633679241878.js"></script>


<script src="/dist/custom.js?1633679241878.js"></script>









</body>

</html>